---
// Hero.astro - Displays the main hero section with title, description and CTA
---
<section id="hero" class="content-section hero-section">
  <div class="title-wrapper">
    <img src="/icon.png" alt="THUDM Icon" class="title-icon" />
    <h1 class="main-title" id="animated-title">TDRM</h1>
  </div>
  <p class="subtitle" id="animated-subtitle">Smooth Reward Models with Temporal Difference for LLM RL and Inference</p>
  <p class="description">Process Reward Model + Online Temporal Difference Training <br> to Train Smooth and Strong Reward Models.   <br>
</p>
  <a href="https://github.com/THUDM/TDRM" class="cta-button">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" class="button-icon" aria-hidden="true">
      <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
    </svg>
    <span class="button-text">Get Started</span>
    <div class="repo-stats">
      <div class="stat-item">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" width="16" fill="currentColor">
          <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.75.75 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25z"></path>
        </svg>
        <span id="hero-stars-count">660</span>
      </div>
      <div class="stat-item">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" width="16" fill="currentColor">
          <path fill-rule="evenodd" d="M5 3.25a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm0 2.122a2.25 2.25 0 10-1.5 0v.878A2.25 2.25 0 005.75 8.5h1.5v2.128a2.251 2.251 0 101.5 0V8.5h1.5a2.25 2.25 0 002.25-2.25v-.878a2.25 2.25 0 10-1.5 0v.878a.75.75 0 01-.75.75h-4.5A.75.75 0 015 6.25v-.878zm3.75 7.378a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm3-8.75a.75.75 0 100-1.5.75.75 0 000 1.5z"></path>
        </svg>
        <span id="hero-forks-count">23</span>
      </div>
    </div>
  </a>
  
  <div class="resources-section">
    <div class="resources-buttons">
      <a href="https://arxiv.org/abs/2509.15110" class="resource-button">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="resource-icon" aria-hidden="true">
          <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8l-6-6z"></path>
          <polyline points="14 2 14 8 20 8"></polyline>
          <line x1="16" y1="13" x2="8" y2="13"></line>
          <line x1="16" y1="17" x2="8" y2="17"></line>
          <polyline points="10 9 9 9 8 9"></polyline>
        </svg>
        <span>Paper</span>
      </a>
      <a href="https://x.com/teortaxesTex/status/1802128370861232374?t=kSFmB4TY6sBmfP_KLBHhig&s=19" class="resource-button">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="resource-icon x-icon" aria-hidden="true">
          <path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"></path>
        </svg>
        <span>tl;dr</span>
      </a>
    </div>
  </div>

  <div class="diagram-placeholder">
    <img src="/teaser.png" alt="Diagram placeholder" style=""/>
    <p style="text-align: center; color: #888;">Overview of TDRM framework and improvement over baseline method.</p>
  </div>
  
  <div class="authors-section">
    <!-- <h3 class="section-title">Authors</h3> -->
    <div class="authors-list">
        <p>
          <a href="https://zhangdan0602.github.io">Dan Zhang</a><sup class="affiliation-marker">*1</sup>,
          <a href="https://henrycai11.github.io">Min Cai</a><sup class="affiliation-marker">*2</sup>,
          <a href="https://jonathanmli.github.io">Jonathan Li</a><sup class="affiliation-marker">3</sup>,
          <a href="https://acbull.github.io">Ziniu Hu</a><sup class="affiliation-marker">3</sup>,
        </p>
        <p>
          <a href="https://www.yisongyue.com">Yisong Yue</a><sup class="affiliation-marker">3</sup>,
          <a href="https://keg.cs.tsinghua.edu.cn/jietang/">Jie Tang</a><sup class="affiliation-marker">1,4</sup>,
        </p>
        <p class="equal-contribution">
          <sup class="affiliation-marker">*</sup> Equal Contribution
        </p>
        <p class="affiliations">
          <sup class="affiliation-marker">1</sup> Department of Computer Science and Technology, Tsinghua University &nbsp;&nbsp;
          <sup class="affiliation-marker">2</sup> University of Alberta &nbsp;&nbsp;<br>
          <sup class="affiliation-marker">3</sup> California Institute of Technology &nbsp;&nbsp;
          <sup class="affiliation-marker">4</sup> School of Electronics and Computer Science, University of Southampton &nbsp;&nbsp;
        </p>
    </div>
  </div>
  <br>
  <div>
<div style="
  background: linear-gradient(to right, #f0d9ff, #e0c3fc); 
  padding: 40px 20px;
  text-align: center;
  border-radius: 12px;
  font-family: sans-serif;
">

  <h3 style="
    font-size: 2.5em; 
    font-weight: 800; 
    color: #1e1e60;
    margin-bottom: 20px;
  ">
    Abstract
  </h3>

  <p style="
    font-size: 1.1em; 
    max-width: 800px; 
    margin: 0 auto; 
    color: #1a1a1a; 
    line-height: 1.6;
  ">
  Reward models are central to both reinforcement learning (RL) with language models and inference-time verification. 
  However, existing reward models often lack temporal consistency, leading to ineffective policy updates and unstable RL training.
  We introduce TDRM, a method for learning smoother and more reliable reward models by minimizing temporal differences (TD) for training-time reinforcement learning and inference-time verification. 
  Experiments show that TD-trained process reward models (PRMs) improve performance across Best-of-$N$ (up to 6.6\%) and tree-search (up to 23.7\%) settings.
  When combined with Reinforcement Learning with Verifiable Rewards (RLVR), TD-trained PRMs lead to more data-efficient RL --- achieving comparable performance with just 2.5k data to what baseline methods require 50.1k data to attain --- and yield higher-quality language model policies in 8 model variants (5 series), e.g., Qwen2.5-(0.5B, 1,5B), GLM4-9B-0414, GLM-Z1-9B-0414, Qwen2.5-Math-(1.5B, 7B), and DeepSeek-R1-Distill-Qwen-(1.5B, 7B).
  </p>
</div>

  </div>
</section> 

<script>
  // Format numbers to show 'k' for thousands
  function formatNumber(num) {
    return num > 999 ? (num / 1000).toFixed(1) + 'k' : num;
  }

  // Fetch GitHub stats directly
  async function fetchGitHubStats() {
    try {
      // Try to use default numbers immediately
      const starsElement = document.getElementById('hero-stars-count');
      const forksElement = document.getElementById('hero-forks-count');
      
      // Fetch latest stats from GitHub
      const response = await fetch('https://api.github.com/repos/THUDM/TDRM');
      const data = await response.json();
      
      const stars = data.stargazers_count;
      const forks = data.forks_count;
      
      // Update stars count if available and different from default
      if (starsElement && stars !== undefined) {
        const formattedStars = formatNumber(stars);
        if (formattedStars !== '1.4k') {
          starsElement.textContent = formattedStars;
        }
      }
      
      // Update forks count if available and different from default
      if (forksElement && forks !== undefined) {
        const formattedForks = formatNumber(forks);
        if (formattedForks !== '105') {
          forksElement.textContent = formattedForks;
        }
      }
    } catch (error) {
      console.error('Error fetching GitHub stats:', error);
      // Keep default values on error
    }
  }

  // Run when page is loaded
  document.addEventListener('DOMContentLoaded', fetchGitHubStats);
</script> 

<style>
  .cta-button {
    display: inline-flex;
    align-items: center;
    gap: 12px;
    padding: 12px 24px;
    background: linear-gradient(45deg, #2a2f6c, #4b4f8f);
    border: none;
    border-radius: 50px;
    color: white;
    font-size: 18px;
    font-weight: 600;
    text-decoration: none;
    transition: all 0.3s ease;
    box-shadow: 0 4px 15px rgba(42, 47, 108, 0.2);
  }

  .cta-button:hover {
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(42, 47, 108, 0.3);
    text-decoration: none;
  }

  .button-icon {
    width: 24px;
    height: 24px;
    fill: currentColor;
  }

  .button-text {
    margin-right: 12px;
  }

  .repo-stats {
    display: flex;
    gap: 16px;
    padding-left: 16px;
    border-left: 1px solid rgba(255, 255, 255, 0.3);
  }

  .stat-item {
    display: flex;
    align-items: center;
    gap: 6px;
    color: white;
    font-size: 16px;
  }

  .stat-item svg {
    fill: currentColor;
  }

  .vagen-announcement {
    color: #2a2f6c;
    font-size: 0.9em;
    text-decoration: none;
    transition: color 0.3s ease;
  }

  .vagen-announcement:hover {
    color: #4b4f8f;
    text-decoration: none;
  }
</style> 
